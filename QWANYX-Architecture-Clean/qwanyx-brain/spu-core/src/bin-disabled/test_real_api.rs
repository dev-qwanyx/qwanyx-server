//! Test des vrais appels API OpenAI

use spu_core::{AIClient, AIConfig};
use std::io::{self, Write};

fn main() {
    println!("ğŸ§  SPU Core - Test RÃ‰EL API OpenAI");
    println!("====================================\n");
    
    // Charger la configuration
    let config = AIConfig::default();
    
    // VÃ©rifier qu'on a une clÃ© API
    match config.api_key {
        Some(ref key) => {
            let masked = format!("sk-...{}", &key[key.len()-4..]);
            println!("âœ… ClÃ© API trouvÃ©e: {}", masked);
        },
        None => {
            println!("âŒ Pas de clÃ© API trouvÃ©e!");
            println!("   Assurez-vous que OPENAI_API_KEY est dÃ©finie dans ../.env");
            return;
        }
    }
    
    // Demander confirmation avant d'utiliser l'API
    print!("\nâš ï¸  Ceci va faire de VRAIS appels API (coÃ»t ~$0.0002).\nContinuer? (o/n): ");
    io::stdout().flush().unwrap();
    
    let mut input = String::new();
    io::stdin().read_line(&mut input).unwrap();
    
    if !input.trim().eq_ignore_ascii_case("o") {
        println!("AnnulÃ©.");
        return;
    }
    
    // CrÃ©er le client (toujours en mode rÃ©el maintenant)
    println!("\nğŸš€ CrÃ©ation du client...");
    let client = AIClient::new();
    
    // Test de compression avec NLM (Nano Language Model)
    println!("\nğŸ“ Test de compression avec NLM (GPT-5-nano â†’ GPT-4o-mini):");
    println!("   â„¹ï¸  NLM = 400k tokens de contexte!");
    
    let text = "urgent meeting about the new product launch strategy";
    
    match client.compress(text, "nlm") {
        Ok(compressed) => {
            println!("   âœ… SuccÃ¨s!");
            println!("   Original: {}", text);
            println!("   CompressÃ©: {}", compressed);
            
            // Test d'expansion
            println!("\nğŸ“– Test d'expansion avec le mÃªme modÃ¨le:");
            match client.expand(&compressed, "nlm") {
                Ok(expanded) => {
                    println!("   âœ… SuccÃ¨s!");
                    println!("   Expanded: {}", expanded);
                },
                Err(e) => {
                    println!("   âŒ Erreur expansion: {:?}", e);
                }
            }
        },
        Err(e) => {
            println!("   âŒ Erreur compression: {:?}", e);
            println!("\nğŸ’¡ VÃ©rifiez:");
            println!("   - Votre clÃ© API est valide");
            println!("   - Vous avez des crÃ©dits OpenAI");
            println!("   - Votre connexion internet fonctionne");
        }
    }
    
    // Test avec diffÃ©rents modÃ¨les
    println!("\nğŸ¯ Test avec les 3 modÃ¨les:");
    
    let long_text = "The quarterly financial report shows significant growth in revenue, with a 25% increase compared to last year. The marketing department's new campaign has been particularly successful.";
    
    // Test NLM (Nano Language Model)
    println!("\n   NLM (compression maximale):");
    match client.compress(long_text, "nlm") {
        Ok(compressed) => {
            println!("   CompressÃ©: {}", compressed);
        },
        Err(e) => {
            println!("   âŒ Erreur: {:?}", e);
        }
    }
    
    // Test MLM (Medium Language Model)
    println!("\n   MLM (compression moyenne):");
    match client.compress(long_text, "mlm") {
        Ok(compressed) => {
            println!("   CompressÃ©: {}", compressed);
        },
        Err(e) => {
            println!("   âŒ Erreur: {:?}", e);
        }
    }
    
    // Test XLM (eXtreme Language Model)
    println!("\n   XLM (compression minimale, plus de dÃ©tail):");
    match client.compress(long_text, "xlm") {
        Ok(compressed) => {
            println!("   CompressÃ©: {}", compressed);
        },
        Err(e) => {
            println!("   âŒ Erreur: {:?}", e);
        }
    }
}